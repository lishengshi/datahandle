<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>

    <groupId>org.bd</groupId>
    <artifactId>datahandle</artifactId>
    <version>1.0-SNAPSHOT</version>
    <packaging>jar</packaging>
    <description>数仓建设处理流程</description>

    <!--配置-->
    <properties>
        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
        <encoding>UTF-8</encoding>
        <scala.version>2.11.8</scala.version>
        <spark.version>2.1.1</spark.version>
        <hadoop.version>2.7.3</hadoop.version>
        <scala.compat.version>2.11</scala.compat.version>
    </properties>

    <dependencies>
        <!-- scala 项目 -->
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-core_2.11</artifactId>
            <version>${spark.version}</version>
            <scope>compile</scope>
            <exclusions>
                <exclusion>
                    <artifactId>slf4j-log4j12</artifactId>
                    <groupId>org.slf4j</groupId>
                </exclusion>
                <exclusion>
                    <artifactId>slf4j-api</artifactId>
                    <groupId>org.slf4j</groupId>
                </exclusion>
            </exclusions>
        </dependency>

        <dependency>
            <groupId>org.slf4j</groupId>
            <artifactId>slf4j-api</artifactId>
            <version>1.7.25</version>
            <scope>compile</scope>
        </dependency>


        <dependency>
            <groupId>org.scala-lang</groupId>
            <artifactId>scala-library</artifactId>
            <version>${scala.version}</version>
            <scope>compile</scope>
        </dependency>

        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-streaming-kafka-0-10_2.11</artifactId>
            <version>${spark.version}</version>
            <scope>compile</scope>
            <exclusions>
                <exclusion>
                    <artifactId>slf4j-log4j12</artifactId>
                    <groupId>org.slf4j</groupId>
                </exclusion>
                <exclusion>
                    <artifactId>slf4j-api</artifactId>
                    <groupId>org.slf4j</groupId>
                </exclusion>
            </exclusions>
        </dependency>

        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-streaming_2.11</artifactId>
            <version>${spark.version}</version>
            <scope>compile</scope>
            <exclusions>
                <exclusion>
                    <artifactId>slf4j-log4j12</artifactId>
                    <groupId>org.slf4j</groupId>
                </exclusion>
                <exclusion>
                    <artifactId>slf4j-api</artifactId>
                    <groupId>org.slf4j</groupId>
                </exclusion>
            </exclusions>
        </dependency>

        <dependency>
            <groupId>org.apache.hbase</groupId>
            <artifactId>hbase-client</artifactId>
            <version>1.3.1</version>
            <exclusions>
                <exclusion>
                    <groupId>org.slf4j</groupId>
                    <artifactId>slf4j-log4j12</artifactId>
                </exclusion>
                <exclusion>
                    <artifactId>slf4j-api</artifactId>
                    <groupId>org.slf4j</groupId>
                </exclusion>
            </exclusions>
            <scope>compile</scope>
        </dependency>

        <dependency>
            <groupId>org.apache.hbase</groupId>
            <artifactId>hbase-server</artifactId>
            <version>1.3.1</version>
            <scope>compile</scope>
            <exclusions>
                <exclusion>
                    <artifactId>slf4j-log4j12</artifactId>
                    <groupId>org.slf4j</groupId>
                </exclusion>
                <exclusion>
                    <artifactId>slf4j-api</artifactId>
                    <groupId>org.slf4j</groupId>
                </exclusion>
            </exclusions>
        </dependency>

        <dependency>
            <groupId>org.spark-project.hive</groupId>
            <artifactId>hive-jdbc</artifactId>
            <version>1.2.1.spark2</version>
            <scope>compile</scope>
            <exclusions>
                <exclusion>
                    <artifactId>slf4j-log4j12</artifactId>
                    <groupId>org.slf4j</groupId>
                </exclusion>
                <exclusion>
                    <artifactId>slf4j-api</artifactId>
                    <groupId>org.slf4j</groupId>
                </exclusion>
            </exclusions>
        </dependency>

        <dependency>
            <groupId>mysql</groupId>
            <artifactId>mysql-connector-java</artifactId>
            <version>5.1.35</version>
            <scope>compile</scope>
        </dependency>

        <dependency>
            <groupId>org.scalikejdbc</groupId>
            <artifactId>scalikejdbc_2.11</artifactId>
            <version>2.5.0</version>
            <scope>compile</scope>
        </dependency>

        <dependency>
            <groupId>org.scalikejdbc</groupId>
            <artifactId>scalikejdbc-config_2.11</artifactId>
            <version>2.5.0</version>
            <scope>compile</scope>
        </dependency>


        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-sql_2.11</artifactId>
            <version>${spark.version}</version>
            <scope>compile</scope>
            <exclusions>
                <exclusion>
                    <artifactId>slf4j-log4j12</artifactId>
                    <groupId>org.slf4j</groupId>
                </exclusion>
                <exclusion>
                    <artifactId>slf4j-api</artifactId>
                    <groupId>org.slf4j</groupId>
                </exclusion>
            </exclusions>
        </dependency>

        <dependency>
            <groupId>org.elasticsearch</groupId>
            <artifactId>elasticsearch-spark-20_2.11</artifactId>
            <version>5.6.11</version>
            <scope>compile</scope>
        </dependency>

        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-hive_2.11</artifactId>
            <version>${spark.version}</version>
            <scope>compile</scope>
            <exclusions>
                <exclusion>
                    <artifactId>slf4j-log4j12</artifactId>
                    <groupId>org.slf4j</groupId>
                </exclusion>
            </exclusions>
        </dependency>

        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-client</artifactId>
            <version>${hadoop.version}</version>
            <scope>compile</scope>
            <exclusions>
                <exclusion>
                    <artifactId>slf4j-log4j12</artifactId>
                    <groupId>org.slf4j</groupId>
                </exclusion>
            </exclusions>
        </dependency>

        <dependency>
            <groupId>redis.clients</groupId>
            <artifactId>jedis</artifactId>
            <version>2.9.0</version>
            <scope>compile</scope>
        </dependency>

        <dependency>
            <groupId>ch.qos.logback</groupId>
            <artifactId>logback-core</artifactId>
            <version>1.2.3</version>
            <scope>compile</scope>
        </dependency>
        <dependency>
            <groupId>ch.qos.logback</groupId>
            <artifactId>logback-classic</artifactId>
            <version>1.2.3</version>
            <scope>compile</scope>
        </dependency>
        <dependency>
            <groupId>ch.qos.logback</groupId>
            <artifactId>logback-access</artifactId>
            <version>1.2.3</version>
            <scope>compile</scope>
        </dependency>

        <dependency>
            <groupId>com.alibaba</groupId>
            <artifactId>druid</artifactId>
            <version>1.1.12</version>
        </dependency>


    </dependencies>
    <build>
        <finalName>datahandle</finalName>
        <resources>
            <resource>
                <directory>src/main/resources</directory>
                <filtering>true</filtering>
            </resource>
            <resource>
                <directory>src/main/resources</directory>
                <includes>
                    <include>connection/*</include>
                </includes>
                <filtering>false</filtering>
            </resource>
            <resource>
                <directory>src/main/resources</directory>
                <includes>
                    <include>template/*</include>
                </includes>
                <filtering>false</filtering>
            </resource>
            <resource>
                <directory>src/main/scala</directory>
                <includes>
                    <include>**.java</include>
                    <include>**.scala</include>
                </includes>
            </resource>
        </resources>

        <plugins>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-compiler-plugin</artifactId>
                <configuration>
                    <source>1.8</source>
                    <target>1.8</target>
                </configuration>
            </plugin>

            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-surefire-plugin</artifactId>
                <version>2.12</version>
                <configuration>
                    <skipTests>true</skipTests>
                    <excludes>
                        <exclude>**/*Test.scala</exclude>
                    </excludes>
                </configuration>
            </plugin>
        </plugins>

    </build>

    <profiles>
        <profile>
            <id>test</id>
            <activation>
                <activeByDefault>true</activeByDefault>
            </activation>
            <properties>
                <jx.mysql.classname>com.mysql.jdbc.Driver</jx.mysql.classname>
                <jx.mysql.jdbcurl>jdbc:mysql://bd3:3306/data?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNull</jx.mysql.jdbcurl>
                <jx.mysql.user>root</jx.mysql.user>
                <jx.mysql.password>12345678</jx.mysql.password>
                <jx.mysql.minPoolSize>5</jx.mysql.minPoolSize>
                <jx.mysql.acquireIncrement>5</jx.mysql.acquireIncrement>
                <jx.mysql.maxPoolSize>100</jx.mysql.maxPoolSize>
                <jx.mysql.maxIdleTime>600</jx.mysql.maxIdleTime>
                <jx.kafka.brokers>jx-newtest-server:9092,jx-newserver-db:9092,bd3:9092</jx.kafka.brokers>
                <jx.kafka.host>jx-newtest-server</jx.kafka.host>
                <jx.zookeeper>jx-newtest-server:2181,jx-newserver-db:2181,bd3:2181</jx.zookeeper>
                <!-- redis -->
                <redis.addr>jx-newtest-server</redis.addr>
                <redis.port>6379</redis.port>
                <redis.auth>KingStarDi1@#</redis.auth>
                <redis.databaseIndex>0</redis.databaseIndex>
                <redis.maxIdle>200</redis.maxIdle>
                <redis.maxActive>1024</redis.maxActive>
                <redis.maxWait>10000</redis.maxWait>
                <redis.timeOut>10000</redis.timeOut>
                <redis.testOnBorrow>true</redis.testOnBorrow>
                <jx.es.host>bd3</jx.es.host>
                <jx.es.cluster.host>jx-newtest-server,jx-newserver-db,bd3</jx.es.cluster.host>
                <jx.es.port>9200</jx.es.port>
                <jx.es.cluster.name>jxkj-data-test-es</jx.es.cluster.name>
            </properties>
        </profile>

        <profile>
            <id>online</id>
            <activation>
                <activeByDefault>true</activeByDefault>
            </activation>
            <properties>
                <jx.mysql.classname>com.mysql.jdbc.Driver</jx.mysql.classname>
                <jx.mysql.jdbcurl>jdbc:mysql://bigdata-server-1:3306/data?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNull</jx.mysql.jdbcurl>
                <jx.mysql.user>root</jx.mysql.user>
                <jx.mysql.password>JingXing-123</jx.mysql.password>
                <jx.mysql.minPoolSize>5</jx.mysql.minPoolSize>
                <jx.mysql.acquireIncrement>5</jx.mysql.acquireIncrement>
                <jx.mysql.maxPoolSize>100</jx.mysql.maxPoolSize>
                <jx.mysql.maxIdleTime>600</jx.mysql.maxIdleTime>
                <jx.kafka.brokers>bigdata-server-2:9092,bigdata-server-3:9092,bigdata-server-4:9092,bigdata-server-5:9092,bigdata-server-6:9092</jx.kafka.brokers>
                <jx.kafka.host>bigdata-server-3</jx.kafka.host>
                <jx.zookeeper>bigdata-server-4:2181,bigdata-server-5:2181,bigdata-server-6:2181</jx.zookeeper>
                <!-- redis -->
                <redis.addr>bigdata-server-3</redis.addr>
                <redis.port>6379</redis.port>
                <redis.auth>Kingstardi</redis.auth>
                <redis.databaseIndex>0</redis.databaseIndex>
                <redis.maxIdle>200</redis.maxIdle>
                <redis.maxActive>1024</redis.maxActive>
                <redis.maxWait>10000</redis.maxWait>
                <redis.timeOut>10000</redis.timeOut>
                <redis.testOnBorrow>true</redis.testOnBorrow>
                <jx.es.host>bigdata-server-3</jx.es.host>
                <jx.es.cluster.host>bigdata-server-1,bigdata-server-2,bigdata-server-3,bigdata-server-4,bigdata-server-5,bigdata-server-6</jx.es.cluster.host>
                <jx.es.port>9200</jx.es.port>
                <jx.es.cluster.name>jx-data-es</jx.es.cluster.name>
            </properties>
        </profile>
    </profiles>

</project>